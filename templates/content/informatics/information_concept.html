{% extends 'base/base.html' %}

{% block title %}
Понятие информации
{% endblock%}


{% block body %}
<h1>Понятие информации</h1>
<p>Информация, если у маленького ребёнка что такое информация, то скорее всего он назовёт слова, которые ассоциируются с
    этим понятием, новости, газеты, слышать, видеть и т.д. </p>
<p>В быту под информацией мф понимаем сообщение, сведения, новость, получаемые из внешнего мира при помощи органов
    чувств (глаза, уши, язык).</p>
<p>Вот перед вами картинка, для одного — это молодая девушка, для другого старая женщина, слепой вообще не воспримет эту
    информацию.</p>
<p>Если углубится в понятие информация, то окажется что она не имеет точного и исчерпывающего определения дело в том,
    что. “Информация” является фундаментальным понятием, как, например, “точка” в геометрии или “масса” в физике.</p>
<p>(в употреблении это слово вошло, во второй половине 20 века. Поэтому в толковых словарях Даля, вы не найдете его
    определения)
</p>
<p>Основатель науки кибернетика Норберт Виннер (1894-1964г.), дал такаю формулировку этому понятию:</p>
<p>Информация – это не материя и не энергия, информация – это информация</p>

<p> <b>Информатика</b> изучает информационные процессы – процессы получения, передачи, обработки и хранения информации. </p>
<p> <b>Информатика</b> - это молодая наука, в школах массово её начали изучать в 80-х годах прошлого столетия, в то время как физику, философию и другие науки изучали ещё со времён Аристотеля.</p>
<p>Информатика тесно связана с вычислительными устройствами, автоматами и роботами. Самым универсальным вычислительным устройством является компьютер.</p>
<p>Или “ЭВМ” – Электронное Вычислительное Устройство/Машина. Само слово “информатика” образовано из двух слов: </p>
<p><b>Информация + Автоматика.</b> В англы язычных странах Информатику называют <b>“Computer Science”</b>-наука о компьютерах.</p>
<h2>Основные разделы информатики:</h2>
<ul>
    <li>Теоретическая информатика – Теория информации, Теория кодирования
    </li>
    <li>Вычислительная техника – Устройство компьютеров и компьютерных сетей </li>
    <li>Алгоритмизация и программирование</li>
    <li>Прикладная информатика – Персональные компьютеры, прикладные программы </li>
    <li>Искусственный интеллект – Распознавание образов, Понимания речи, Машинный перевод
    </li>
</ul>
<h3>Понятие информации с точки зрения технических устройств
</h3>
<p>С развитием устройств связи и вычислительной техники, у инженеров появилась потребность в измерении и изучении систем передачи информации.
</p>
<p>Теория связи была разработана в прошлом веке американским инженером <b>Клодом Шенноном</b> (1916-2001) – основателем теории информатики. 
</p>
<p>(Единица измерения “БИТ” в первые была предложена этим учёным в 1948 году) </p>
<p>В технических устройствах, сообщения передаются в виде: сигналов, световых, электрических и т.д., которые регистрируются датчиками, сигналы формируются источником и передаются приемнику по каналу связи. Для передачи сообщения его нужно закодировать, сообщение, зафиксированное в виде кодов устройства, называют “данными” после обработки интерпретации декодирования последующие его осмыслению, они превращаются в информацию, для извлечения смысла из сигналов, человек использует знания.</p>
<h4>Понятие информации с точки зрения биологии</h4>
<p>В течении многих миллионов лет, на земле наблюдается эволюционный процесс, усложнение организмов что ведёт к увеличению информации. Мы воспринимаем информацию при помощи пяти органов чувств:</p>
<ul>
    <li>Зрительное, визуальное </li>
    <li>Звуковая, аудиальная </li>
    <li>Вкусовая, вкус</li>
    <li>Обаятельное, запахи </li>
    <li>Тактильное, осязание
    </li>
</ul>
<p>Животные и растения представляют собой сложные организмы, внутри которых непрерывно происходит обмен информации между органами с помощью нервных волокон и нейронов, в молекулах ДНК генов живых организмов содержится генетическая информация которые хранится в клетках и передается по наследству.</p>
<h4>Понятие информации с точки зрения физики</h4>
<p>С точки зрения физики информация является мерой упорядоченности и сложности системы. В физике мерой беспорядка (хаоса) для термодинамической системы является <b>энтропия системы.</b> </p>
<p>По мере увеличения сложности системы величина энтропии уменьшается, и величина информации увеличивается.</p>
<h5>
    Понятие информации с точки зрения философии
    </h5>
  <p><b>Атрибутивная концепция:</b> Информация – это объективное внутреннее свойство всех материальных объектов, она содержится во всех без исключения элементах системных материального мира. </p>
  <p><b>Функциональная концепция: </b>Информация является неотъемлемым атрибутом живых организмов и человеческого общества.</p>
  <p><b>Ареоцентрическая концепция:</b> Информация трактуется как знание, причём не любое знание, а та его часть, которая используется для ориентировки, для активного действия, для управления и самоуправления. Информация должна иметь смысл.</p>  
<p><b>Например
    МОСКВА – столица РОСИИ</b></p>
 <p><b>Атрибутивная концепция: </b>Набор букв, имеет материальную сущность и содержит информацию, независимо от того будут его читать или нет.</p>
 <p><b>Функциональная концепция:</b> Информация может быть зарегистрирована зрительным живыми организмами и датчиками технических устройств.</p>
 <p><b>Ареоцентрическая концепция:</b> Конструкция, которая может быть прочитана и интерпретирована человеком, но информация эта носит субъективный характер.</p>
 <p>(Для многих россиянин оно не добавляет новых знаний, для китайца, который не знает русский язык — это тоже не информация, а набор букв)</p>   
<h6>Свойства информации</h6>
    <ul>
    <li>- объективность (независимость от чьего-либо мнения) </li>
    <li>- понятность (понятно для получателя)</li>
    <li>- полезность (позволяет получателю решать свои задачи) </li>
    <li>- достоверность (получено из надёжного источника) </li>
    <li>- актуальность (значимость в данном момент)</li>
    </ul>























{% endblock%}